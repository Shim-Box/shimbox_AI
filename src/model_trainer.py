# src/model_trainer.py
import warnings
warnings.filterwarnings("ignore")

from pathlib import Path
from typing import List

import joblib
import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline

# ====== ê²½ë¡œ ì•ˆì „í™” ======
# project-root/
#   â”œâ”€ data/processed/processed_logistics_data.csv
#   â””â”€ models/optimal_capacity_predictor.pkl
ROOT = Path(__file__).resolve().parents[1]
DATA_PATH = ROOT / "data" / "processed" / "processed_logistics_data.csv"
MODEL_SAVE_PATH = ROOT / "models" / "optimal_capacity_predictor.pkl"

# ====== ê³ ì • Feature / Target ======
FEATURES: List[str] = [
    "skill", "total_work_hours", "delivery_count_yesterday", "bmi", "bmr",
    "avg_heart_rate", "steps", "load_rel", "strain", "wish", "driver_id",
    "time_per_delivery", "deliveries_per_hour", "steps_per_hour",
    "steps_per_delivery", "hr_per_step", "hr_per_hour",
]
TARGET = "theta_target"


def _make_ohe():
    """sklearn ë²„ì „ë³„ OneHotEncoder í˜¸í™˜ ì²˜ë¦¬."""
    from sklearn.preprocessing import OneHotEncoder
    try:
        # sklearn >= 1.2
        return OneHotEncoder(handle_unknown="ignore", sparse_output=False)
    except TypeError:
        # sklearn < 1.2
        return OneHotEncoder(handle_unknown="ignore", sparse=False)


def _coerce_numeric(df: pd.DataFrame, cols: List[str]) -> pd.DataFrame:
    """ì§€ì •í•œ ì»¬ëŸ¼ì„ ìˆ«ìí˜•ìœ¼ë¡œ ì•ˆì „ ë³€í™˜ (ê²°ì¸¡ì€ 0 ëŒ€ì²´)."""
    for c in cols:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")
    return df


def train_and_save_model():
    if not DATA_PATH.exists():
        print(f"âŒ ì˜¤ë¥˜: ë°ì´í„° íŒŒì¼ '{DATA_PATH}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("â¡ ë¨¼ì € ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•´ processed CSVë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        return None

    print("\n--- ë°ì´í„° ë¡œë“œ ---")
    df = pd.read_csv(DATA_PATH)

    # ì»¬ëŸ¼ ë³´ì •/ì ê²€

    if "driver_id" not in df.columns and "courier_id" in df.columns:
        df["driver_id"] = df["courier_id"].astype(str)

    # ëˆ„ë½ ì»¬ëŸ¼ ì²´í¬
    missing = [c for c in FEATURES + [TARGET] if c not in df.columns]
    if missing:
        raise ValueError(f"ë°ì´í„°ì— ë‹¤ìŒ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}")

    # ê²°ì¸¡ì¹˜ 1ì°¨ ì²˜ë¦¬ (ë²”ì£¼í˜•/ì‹ë³„ì)
    df["skill"] = df["skill"].fillna("unknown").astype(str)
    df["driver_id"] = df["driver_id"].fillna("unknown").astype(str)

    # ìˆ«ìí˜• í›„ë³´
    categorical_features = ["skill", "driver_id"]
    numerical_features = [f for f in FEATURES if f not in categorical_features]

    # ìˆ«ìí˜• ë³€í™˜ + ê²°ì¸¡ ë³´ì •
    df = _coerce_numeric(df, numerical_features + [TARGET]).fillna(0)

    # Train/Test Split
    X = df[FEATURES]
    y = df[TARGET]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # ì „ì²˜ë¦¬/ëª¨ë¸ íŒŒì´í”„ë¼ì¸
    ohe = _make_ohe()
    preprocessor = ColumnTransformer(
        transformers=[
            ("cat", ohe, categorical_features),
            ("num", "passthrough", numerical_features),
        ],
        remainder="drop",
    )

    # XGBoost ê°€ì ¸ì˜¤ê¸°
    try:
        from xgboost import XGBRegressor
    except Exception as e:
        raise RuntimeError(
            "xgboostê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. requirements.txtì— 'xgboost'ë¥¼ ì¶”ê°€í•˜ê³  ì„¤ì¹˜í•˜ì„¸ìš”."
        ) from e

    xgb_model = XGBRegressor(
        n_estimators=300,
        learning_rate=0.05,
        max_depth=6,
        subsample=0.9,
        colsample_bytree=0.9,
        random_state=42,
        tree_method="hist",
    )

    model_pipeline = Pipeline(
        steps=[("preprocessor", preprocessor), ("regressor", xgb_model)]
    )

    print("\n--- ëª¨ë¸ í•™ìŠµ ì‹œì‘ (theta_target ì˜ˆì¸¡) ---")
    model_pipeline.fit(X_train, y_train)
    print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ.")

    # í‰ê°€
    y_pred = model_pipeline.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print("\nğŸ“Š í‰ê°€ ê²°ê³¼")
    print(f"   â€¢ RÂ² Score : {r2:.4f}")
    print(f"   â€¢ MAE      : {mae:.4f}")

    # ì €ì¥
    MODEL_SAVE_PATH.parent.mkdir(parents=True, exist_ok=True)
    joblib.dump(model_pipeline, MODEL_SAVE_PATH)
    print(f"\nğŸ’¾ ëª¨ë¸ì´ '{MODEL_SAVE_PATH}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n")

    return model_pipeline


if __name__ == "__main__":
    train_and_save_model()
